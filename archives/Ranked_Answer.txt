Question: What is the price per 1M input tokens of the llama-2-7b-chat-fp16 model?
Rank 1 Answer Chunk:
Text Generation â€¢ Meta Quantized (int8) generative text model with 7 billion parameters from Meta m2m100-1.2b Translation â€¢ Meta Multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation Batch resnet-50 Image Classification â€¢ Microsoft 50 layers deep image classification CNN trained on more than 1M images from ImageNet whisper Automatic Speech Recognition â€¢ OpenAI Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. llama-3.1-70b-instruct Text Generation â€¢ Meta The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. Was this helpful? Previous Dashboard Next Workers Bindings Resources API New to Cloudflare? Products Sponsorships Open Source Support Help Center System Status Compliance GDPR Company cloudflare.com Our team Careers Tools Cloudflare Radar Speed Test Is BGP Safe Yet? RPKI Toolkit Certificate Transparency Community X Discord YouTube GitHub 2025 Cloudflare, Inc. Privacy Policy Terms of Use Report Security Issues Trademark Cookie Preferences === Content from https://developers.cloudflare.com/workers-ai/ === Products Workers AI Cloudflare Workers AI Copy Page Run machine learning models, powered by serverless GPUs, on Cloudflare's global network. Available on Free and Paid plans Workers AI allows you to run AI models in a serverless way, without having to worry about scaling, maintaining, or paying for unused infrastructure. You can invoke models running on GPUs on Cloudflare's network from your own code â€” from Workers, Pages, or anywhere via the Cloudflare API. Workers AI gives you access to: 50+ open-source models, available as a part of our model catalog Serverless, pay-for-what-you-use pricing model All as part of a fully-featured developer platform, including AI Gateway, Vectorize, Workers and more... Get started Watch a Workers AI demo Custom requirements If you have custom requirements like private custom models or higher limits, complete the Custom Requirements Form â†—. Cloudflare will contact you with next steps. Workers AI is now Generally Available To report bugs or give feedback, go to the #workers-ai Discord channel â†—. If you are having issues with Wrangler, report issues in the Wrangler GitHub repository â†—. Features Models Workers AI comes with a curated set of popular open-source models that enable you to do tasks such as image classification, text generation, object detection and more. Browse models Related products AI Gateway Observe and control your AI applications with caching, rate limiting, request retries, model fallback, and more. Vectorize Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM. Workers Build serverless applications and deploy instantly across the globe for exceptional performance, reliability, and scale. Pages Create full-stack applications that are instantly deployed
Rank 2 Answer Chunk:
nousresearch meta-llama Meta llava-hf myshell-ai MistralAI MistralAI openchat Microsoft Qwen defog runwayml Stability.ai bytedance nexusflow tinyllama unum fblgit OpenAI ðŸ“Œ llama-4-scout-17b-16e-instruct Text Generation â€¢ Meta Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding. Function calling ðŸ“Œ llama-3.3-70b-instruct-fp8-fast Text Generation â€¢ Meta Llama 3.3 70B quantized to fp8 precision, optimized to be faster. Batch Function calling ðŸ“Œ llama-3.1-8b-instruct-fast Text Generation â€¢ Meta [Fast version] The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. gemma-3-12b-it Text Generation â€¢ Google Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Gemma 3 models are multimodal, handling text and image input and generating text output, with a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. LoRA mistral-small-3.1-24b-instruct Text Generation â€¢ MistralAI Building upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance. With 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks. Function calling qwq-32b Text Generation â€¢ Qwen QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini. LoRA qwen2.5-coder-32b-instruct Text Generation â€¢ Qwen Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5: LoRA B bge-reranker-base Text Classification â€¢ baai Different from embedding model, reranker uses question and document as input and directly output similarity instead of embedding. You can get a relevance score by inputting query and passage to the reranker. And the score can be mapped to a float value in [0,1] by sigmoid function. llama-guard-3-8b Text Generation â€¢ Meta Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM â€“ it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated. LoRA deepseek-r1-distill-qwen-32b Text Generation â€¢ DeepSeek DeepSeek-R1-Distill-Qwen-32B is a model
Rank 3 Answer Chunk:
Beta Image-to-Text â€¢ unum UForm-Gen is a small generative vision-language model primarily designed for Image Captioning and Visual Question Answering. The model was pre-trained on the internal image captioning dataset and fine-tuned on public instructions datasets: SVIT, LVIS, VQAs datasets. F bart-large-cnn Beta Summarization â€¢ facebook BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. You can use this model for text summarization. phi-2 Beta Text Generation â€¢ Microsoft Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding. T tinyllama-1.1b-chat-v1.0 Beta Text Generation â€¢ tinyllama The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T. qwen1.5-14b-chat-awq Beta Text Generation â€¢ Qwen Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization. qwen1.5-7b-chat-awq Beta Text Generation â€¢ Qwen Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization. qwen1.5-0.5b-chat Beta Text Generation â€¢ Qwen Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. T discolm-german-7b-v1-awq Beta Text Generation â€¢ thebloke DiscoLM German 7b is a Mistral-based large language model with a focus on German-language applications. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization. T falcon-7b-instruct Beta Text Generation â€¢ tiiuae Falcon-7B-Instruct is a 7B parameters causal decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. O openchat-3.5-0106 Beta Text Generation â€¢ openchat OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning. D sqlcoder-7b-2 Beta Text Generation â€¢ defog This model is intended to be used by non-technical users to understand data inside their SQL databases. deepseek-math-7b-instruct Beta Text Generation â€¢ DeepSeek DeepSeekMath-Instruct 7B is a mathematically instructed tuning model derived from DeepSeekMath-Base 7B. DeepSeekMath is initialized with DeepSeek-Coder-v1.5 7B and continues pre-training on math-related tokens sourced from Common Crawl, together with natural language and code data for 500B tokens. F detr-resnet-50 Beta Object Detection â€¢ facebook DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). B stable-diffusion-xl-lightning Beta Text-to-Image â€¢ bytedance SDXL-Lightning is a lightning-fast text-to-image generation model. It can generate high-quality 1024px images in a few steps. L dreamshaper-8-lcm Beta Text-to-Image â€¢ lykon Stable Diffusion model that has been fine-tuned to be better at photorealism without sacrificing range. R stable-diffusion-v1-5-img2img Beta Text-to-Image â€¢ runwayml Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images. Img2img generate a new image from an input image with Stable Diffusion. R stable-diffusion-v1-5-inpainting Beta Text-to-Image â€¢ runwayml Stable Diffusion Inpainting is
============================================================
Question: What is the maximum number of tokens that can be generated in a single request?
Rank 1 Answer Chunk:
Text Generation â€¢ Meta Quantized (int8) generative text model with 7 billion parameters from Meta m2m100-1.2b Translation â€¢ Meta Multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation Batch resnet-50 Image Classification â€¢ Microsoft 50 layers deep image classification CNN trained on more than 1M images from ImageNet whisper Automatic Speech Recognition â€¢ OpenAI Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. llama-3.1-70b-instruct Text Generation â€¢ Meta The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. Was this helpful? Previous Dashboard Next Workers Bindings Resources API New to Cloudflare? Products Sponsorships Open Source Support Help Center System Status Compliance GDPR Company cloudflare.com Our team Careers Tools Cloudflare Radar Speed Test Is BGP Safe Yet? RPKI Toolkit Certificate Transparency Community X Discord YouTube GitHub 2025 Cloudflare, Inc. Privacy Policy Terms of Use Report Security Issues Trademark Cookie Preferences === Content from https://developers.cloudflare.com/workers-ai/ === Products Workers AI Cloudflare Workers AI Copy Page Run machine learning models, powered by serverless GPUs, on Cloudflare's global network. Available on Free and Paid plans Workers AI allows you to run AI models in a serverless way, without having to worry about scaling, maintaining, or paying for unused infrastructure. You can invoke models running on GPUs on Cloudflare's network from your own code â€” from Workers, Pages, or anywhere via the Cloudflare API. Workers AI gives you access to: 50+ open-source models, available as a part of our model catalog Serverless, pay-for-what-you-use pricing model All as part of a fully-featured developer platform, including AI Gateway, Vectorize, Workers and more... Get started Watch a Workers AI demo Custom requirements If you have custom requirements like private custom models or higher limits, complete the Custom Requirements Form â†—. Cloudflare will contact you with next steps. Workers AI is now Generally Available To report bugs or give feedback, go to the #workers-ai Discord channel â†—. If you are having issues with Wrangler, report issues in the Wrangler GitHub repository â†—. Features Models Workers AI comes with a curated set of popular open-source models that enable you to do tasks such as image classification, text generation, object detection and more. Browse models Related products AI Gateway Observe and control your AI applications with caching, rate limiting, request retries, model fallback, and more. Vectorize Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM. Workers Build serverless applications and deploy instantly across the globe for exceptional performance, reliability, and scale. Pages Create full-stack applications that are instantly deployed
Rank 2 Answer Chunk:
=== Content from https://developers.cloudflare.com/ai-gateway/ === Products AI Gateway Cloudflare AI Gateway Copy Page Observe and control your AI applications. Available on all plans Cloudflare's AI Gateway allows you to gain visibility and control over your AI apps. By connecting your apps to AI Gateway, you can gather insights on how people are using your application with analytics and logging and then control how your application scales with features such as caching, rate limiting, as well as request retries, model fallback, and more. Better yet - it only takes one line of code to get started. Check out the Get started guide to learn how to configure your applications with AI Gateway. Features Analytics View metrics such as the number of requests, tokens, and the cost it takes to run your application. View Analytics Logging Gain insight on requests and errors. View Logging Caching Serve requests directly from Cloudflare's cache instead of the original model provider for faster requests and cost savings. Use Caching Rate limiting Control how your application scales by limiting the number of requests your application receives. Use Rate limiting Request retry and fallback Improve resilience by defining request retry and model fallbacks in case of an error. Use Request retry and fallback Your favorite providers Workers AI, OpenAI, Azure OpenAI, HuggingFace, Replicate, and more work with AI Gateway. Use Your favorite providers Related products Workers AI Run machine learning models, powered by serverless GPUs, on Cloudflareâ€™s global network. Vectorize Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM. More resources Developer Discord Connect with the Workers community on Discord to ask questions, show what you are building, and discuss the platform with other developers. Use cases Learn how you can build and deploy ambitious AI applications to Cloudflare's global network. @CloudflareDev Follow @CloudflareDev on Twitter to learn about product announcements, and what is new in Cloudflare Workers. Edit page Last updated: Mar 14, 2025 Next Getting started Resources API New to Cloudflare? Products Sponsorships Open Source Support Help Center System Status Compliance GDPR Company cloudflare.com Our team Careers Tools Cloudflare Radar Speed Test Is BGP Safe Yet? RPKI Toolkit Certificate Transparency Community X Discord YouTube GitHub 2025 Cloudflare, Inc. Privacy Policy Terms of Use Report Security Issues Trademark Cookie Preferences === Content from https://developers.cloudflare.com/workers-ai/models/ === Products Workers AI Models Models Copy Page â–¼ TASKS Summarization Text Embeddings Text Classification Text Generation Object Detection Text-to-Image Image-to-Text Translation Text-to-Speech Image Classification Automatic Speech Recognition â–¼ CAPABILITIES Batch LoRA Function calling â–¼ AUTHORS facebook baai thebloke DeepSeek HuggingFace lykon tiiuae Black Forest Labs Google nousresearch meta-llama Meta llava-hf myshell-ai MistralAI MistralAI openchat Microsoft Qwen defog runwayml Stability.ai bytedance nexusflow tinyllama unum fblgit OpenAI ðŸ“Œ llama-4-scout-17b-16e-instruct Text Generation â€¢ Meta Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer
Rank 3 Answer Chunk:
nousresearch meta-llama Meta llava-hf myshell-ai MistralAI MistralAI openchat Microsoft Qwen defog runwayml Stability.ai bytedance nexusflow tinyllama unum fblgit OpenAI ðŸ“Œ llama-4-scout-17b-16e-instruct Text Generation â€¢ Meta Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding. Function calling ðŸ“Œ llama-3.3-70b-instruct-fp8-fast Text Generation â€¢ Meta Llama 3.3 70B quantized to fp8 precision, optimized to be faster. Batch Function calling ðŸ“Œ llama-3.1-8b-instruct-fast Text Generation â€¢ Meta [Fast version] The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. gemma-3-12b-it Text Generation â€¢ Google Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Gemma 3 models are multimodal, handling text and image input and generating text output, with a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. LoRA mistral-small-3.1-24b-instruct Text Generation â€¢ MistralAI Building upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance. With 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks. Function calling qwq-32b Text Generation â€¢ Qwen QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini. LoRA qwen2.5-coder-32b-instruct Text Generation â€¢ Qwen Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5: LoRA B bge-reranker-base Text Classification â€¢ baai Different from embedding model, reranker uses question and document as input and directly output similarity instead of embedding. You can get a relevance score by inputting query and passage to the reranker. And the score can be mapped to a float value in [0,1] by sigmoid function. llama-guard-3-8b Text Generation â€¢ Meta Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM â€“ it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated. LoRA deepseek-r1-distill-qwen-32b Text Generation â€¢ DeepSeek DeepSeek-R1-Distill-Qwen-32B is a model
============================================================
Question: What is the maximum number of concurrent requests that can be made to the API?
Rank 1 Answer Chunk:
=== Content from https://developers.cloudflare.com/ai-gateway/ === Products AI Gateway Cloudflare AI Gateway Copy Page Observe and control your AI applications. Available on all plans Cloudflare's AI Gateway allows you to gain visibility and control over your AI apps. By connecting your apps to AI Gateway, you can gather insights on how people are using your application with analytics and logging and then control how your application scales with features such as caching, rate limiting, as well as request retries, model fallback, and more. Better yet - it only takes one line of code to get started. Check out the Get started guide to learn how to configure your applications with AI Gateway. Features Analytics View metrics such as the number of requests, tokens, and the cost it takes to run your application. View Analytics Logging Gain insight on requests and errors. View Logging Caching Serve requests directly from Cloudflare's cache instead of the original model provider for faster requests and cost savings. Use Caching Rate limiting Control how your application scales by limiting the number of requests your application receives. Use Rate limiting Request retry and fallback Improve resilience by defining request retry and model fallbacks in case of an error. Use Request retry and fallback Your favorite providers Workers AI, OpenAI, Azure OpenAI, HuggingFace, Replicate, and more work with AI Gateway. Use Your favorite providers Related products Workers AI Run machine learning models, powered by serverless GPUs, on Cloudflareâ€™s global network. Vectorize Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM. More resources Developer Discord Connect with the Workers community on Discord to ask questions, show what you are building, and discuss the platform with other developers. Use cases Learn how you can build and deploy ambitious AI applications to Cloudflare's global network. @CloudflareDev Follow @CloudflareDev on Twitter to learn about product announcements, and what is new in Cloudflare Workers. Edit page Last updated: Mar 14, 2025 Next Getting started Resources API New to Cloudflare? Products Sponsorships Open Source Support Help Center System Status Compliance GDPR Company cloudflare.com Our team Careers Tools Cloudflare Radar Speed Test Is BGP Safe Yet? RPKI Toolkit Certificate Transparency Community X Discord YouTube GitHub 2025 Cloudflare, Inc. Privacy Policy Terms of Use Report Security Issues Trademark Cookie Preferences === Content from https://developers.cloudflare.com/workers-ai/models/ === Products Workers AI Models Models Copy Page â–¼ TASKS Summarization Text Embeddings Text Classification Text Generation Object Detection Text-to-Image Image-to-Text Translation Text-to-Speech Image Classification Automatic Speech Recognition â–¼ CAPABILITIES Batch LoRA Function calling â–¼ AUTHORS facebook baai thebloke DeepSeek HuggingFace lykon tiiuae Black Forest Labs Google nousresearch meta-llama Meta llava-hf myshell-ai MistralAI MistralAI openchat Microsoft Qwen defog runwayml Stability.ai bytedance nexusflow tinyllama unum fblgit OpenAI ðŸ“Œ llama-4-scout-17b-16e-instruct Text Generation â€¢ Meta Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer
Rank 2 Answer Chunk:
Text Generation â€¢ Meta Quantized (int8) generative text model with 7 billion parameters from Meta m2m100-1.2b Translation â€¢ Meta Multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation Batch resnet-50 Image Classification â€¢ Microsoft 50 layers deep image classification CNN trained on more than 1M images from ImageNet whisper Automatic Speech Recognition â€¢ OpenAI Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. llama-3.1-70b-instruct Text Generation â€¢ Meta The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. Was this helpful? Previous Dashboard Next Workers Bindings Resources API New to Cloudflare? Products Sponsorships Open Source Support Help Center System Status Compliance GDPR Company cloudflare.com Our team Careers Tools Cloudflare Radar Speed Test Is BGP Safe Yet? RPKI Toolkit Certificate Transparency Community X Discord YouTube GitHub 2025 Cloudflare, Inc. Privacy Policy Terms of Use Report Security Issues Trademark Cookie Preferences === Content from https://developers.cloudflare.com/workers-ai/ === Products Workers AI Cloudflare Workers AI Copy Page Run machine learning models, powered by serverless GPUs, on Cloudflare's global network. Available on Free and Paid plans Workers AI allows you to run AI models in a serverless way, without having to worry about scaling, maintaining, or paying for unused infrastructure. You can invoke models running on GPUs on Cloudflare's network from your own code â€” from Workers, Pages, or anywhere via the Cloudflare API. Workers AI gives you access to: 50+ open-source models, available as a part of our model catalog Serverless, pay-for-what-you-use pricing model All as part of a fully-featured developer platform, including AI Gateway, Vectorize, Workers and more... Get started Watch a Workers AI demo Custom requirements If you have custom requirements like private custom models or higher limits, complete the Custom Requirements Form â†—. Cloudflare will contact you with next steps. Workers AI is now Generally Available To report bugs or give feedback, go to the #workers-ai Discord channel â†—. If you are having issues with Wrangler, report issues in the Wrangler GitHub repository â†—. Features Models Workers AI comes with a curated set of popular open-source models that enable you to do tasks such as image classification, text generation, object detection and more. Browse models Related products AI Gateway Observe and control your AI applications with caching, rate limiting, request retries, model fallback, and more. Vectorize Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM. Workers Build serverless applications and deploy instantly across the globe for exceptional performance, reliability, and scale. Pages Create full-stack applications that are instantly deployed
Rank 3 Answer Chunk:
and in LLM responses (response classification). It acts as an LLM â€“ it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated. LoRA deepseek-r1-distill-qwen-32b Text Generation â€¢ DeepSeek DeepSeek-R1-Distill-Qwen-32B is a model distilled from DeepSeek-R1 based on Qwen2.5. It outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models. llama-3.2-1b-instruct Text Generation â€¢ Meta The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. llama-3.2-3b-instruct Text Generation â€¢ Meta The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. llama-3.2-11b-vision-instruct Text Generation â€¢ Meta The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. LoRA flux-1-schnell Text-to-Image â€¢ Black Forest Labs FLUX.1 [schnell] is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions. llama-3.1-8b-instruct-awq Text Generation â€¢ Meta Quantized (int4) generative text model with 8 billion parameters from Meta. llama-3.1-8b-instruct-fp8 Text Generation â€¢ Meta Llama 3.1 8B quantized to FP8 precision M melotts Text-to-Speech â€¢ myshell-ai MeloTTS is a high-quality multi-lingual text-to-speech library by MyShell.ai. llama-3.1-8b-instruct Text Generation â€¢ Meta The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. B bge-m3 Text Embeddings â€¢ baai Multi-Functionality, Multi-Linguality, and Multi-Granularity embeddings model. Batch M meta-llama-3-8b-instruct Text Generation â€¢ meta-llama Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning. whisper-large-v3-turbo Automatic Speech Recognition â€¢ OpenAI Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. llama-3-8b-instruct-awq Text Generation â€¢ Meta Quantized (int4) generative text model with 8 billion parameters from Meta. L llava-1.5-7b-hf Beta Image-to-Text â€¢ llava-hf LLaVA is an open-source chatbot trained by fine-tuning LLaMA/Vicuna on GPT-generated multimodal instruction-following data. It is an auto-regressive language model, based on the transformer architecture. F una-cybertron-7b-v2-bf16 Beta Text Generation â€¢ fblgit Cybertron 7B v2 is a 7B MistralAI based model, best on it's series. It was trained with SFT, DPO and UNA (Unified Neural Alignment) on multiple datasets. whisper-tiny-en Beta Automatic Speech Recognition â€¢ OpenAI Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. This is the English-only version of the Whisper Tiny model which was trained on the task of speech recognition. llama-3-8b-instruct Text Generation â€¢ Meta Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved
============================================================
