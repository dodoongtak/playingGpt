{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b75eebb-fcb6-4eee-af31-679713a6967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://gist.githubusercontent.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223/raw/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"document.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3db2b1d7-be83-4ecd-b1fe-28e73263e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Q: Is Aaronson guilty?\n",
      "üìù A: Based on the context provided, it seems that Aaronson is indeed guilty of being motivated by self-interest and a lack of compassion for others. The text suggests that he wants to save himself from the challenges posed by the intelligent lunatic, and in doing so, is willing to disregard the suffering of the other person. This lack of empathy and concern for the well-being of another human being can be seen as a guilty trait.\n",
      "\n",
      "Note: My interpretation is grounded in the text's emphasis on Aaronson's self-preservation and lack of emotional investment in the plight of others, which I believe reflects his guilt.\n",
      "==================================================\n",
      "üß† Q: What message did he write in the table?\n",
      "üìù A: The question doesn't mention a specific text or document, so I'll assume it's referring to the provided context.\n",
      "\n",
      "There is no indication that O'Brien wrote any message in a table. The context only describes a conversation between Winston and O'Brien, with some physical interactions like tooth extraction. If you meant something else, please clarify the question!\n",
      "==================================================\n",
      "üß† Q: Who is Julia?\n",
      "üìù A: Julia is not explicitly mentioned in this passage, so I cannot provide a direct answer about her identity.\n",
      "\n",
      "However, considering the context and tone of the text, it's possible to infer that Julia might be a significant figure in Winston's life. The conversation between the narrator (Winston) and O'Brien suggests that they have had previous interactions and are discussing their shared understanding of a world where love and hatred coexist. Since Julia is not mentioned explicitly, we cannot confirm her presence or role in this scene.\n",
      "\n",
      "Note: My answer primarily focuses on the text's content, avoiding making wild assumptions or adding facts not grounded in the text's spirit. I'm leaving the possibility open for Julia's existence or significance in Winston's life, as hinted by the conversation between Winston and O'Brien.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∂àÎü¨Ïò§Í∏∞\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "custom_rag_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "# Role\n",
    "You are a thoughtful and sensitive assistant, skilled at interpreting literary texts.\n",
    "\n",
    "You will answer questions based on the **given document content**, but you are allowed to:\n",
    "- Carefully **interpret symbolic, emotional, or psychological meanings**.\n",
    "- Make **plausible inferences** if strongly suggested by the text.\n",
    "- Prioritize **faithfulness to the text‚Äôs atmosphere and tone**.\n",
    "\n",
    "Rules:\n",
    "- Base your answers primarily on the document.\n",
    "- If the document implies an answer emotionally or symbolically, you may explain it carefully.\n",
    "- Avoid making wild assumptions or adding facts not grounded in the text's spirit.\n",
    "- When necessary, explain your interpretation briefly.\n",
    "\n",
    "Answer format:\n",
    "- First, give a direct answer (2‚Äì4 sentences).\n",
    "- Then, optionally add a short note on the reasoning (1‚Äì2 sentences).\n",
    "\n",
    "Be gentle, thoughtful, and stay close to the text‚Äôs emotions and meanings.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Q: {question}\n",
    "A:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 2. Ollama Î™®Îç∏ Ï§ÄÎπÑ\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 3. Î¨∏ÏÑú Î°úÎìú\n",
    "loader = TextLoader(\"document.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 4. Î¨∏ÏÑú Ï™ºÍ∞úÍ∏∞ (chunking)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 5. Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ ÎßåÎì§Í∏∞ (ÏûÑÎ≤†Îî© Ï†ÄÏû•)\n",
    "embedding_model = OllamaEmbeddings(model=\"llama3\")\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "# 6. Retriever Ï§ÄÎπÑ\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 7. Retrieval QA Ï≤¥Ïù∏ ÎßåÎì§Í∏∞\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    memory=memory,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": custom_rag_prompt,  \n",
    "    }\n",
    ")\n",
    "\n",
    "# 8. ÏßàÎ¨∏ÌïòÍ∏∞\n",
    "questions = [\n",
    "    \"Is Aaronson guilty?\",\n",
    "    \"What message did he write in the table?\",\n",
    "    \"Who is Julia?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"üß† Q: {q}\")\n",
    "    response = qa_chain.invoke({\"query\": q})\n",
    "    print(f\"üìù A: {response['result']}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27a73c-9eda-4a00-a768-5771d7acf34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
