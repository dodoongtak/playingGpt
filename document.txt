

=== Content from https://developers.cloudflare.com/ai-gateway/ ===

Products
AI Gateway
Cloudflare AI Gateway
Copy Page

Observe and control your AI applications.

Available on all plans

Cloudflare's AI Gateway allows you to gain visibility and control over your AI apps. By connecting your apps to AI Gateway, you can gather insights on how people are using your application with analytics and logging and then control how your application scales with features such as caching, rate limiting, as well as request retries, model fallback, and more. Better yet - it only takes one line of code to get started.

Check out the Get started guide to learn how to configure your applications with AI Gateway.

Features
Analytics

View metrics such as the number of requests, tokens, and the cost it takes to run your application.

View Analytics
Logging

Gain insight on requests and errors.

View Logging
Caching

Serve requests directly from Cloudflare's cache instead of the original model provider for faster requests and cost savings.

Use Caching
Rate limiting

Control how your application scales by limiting the number of requests your application receives.

Use Rate limiting
Request retry and fallback

Improve resilience by defining request retry and model fallbacks in case of an error.

Use Request retry and fallback
Your favorite providers

Workers AI, OpenAI, Azure OpenAI, HuggingFace, Replicate, and more work with AI Gateway.

Use Your favorite providers
Related products
Workers AI

Run machine learning models, powered by serverless GPUs, on Cloudflareâ€™s global network.

Vectorize

Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM.

More resources

Developer Discord

Connect with the Workers community on Discord to ask questions, show what you are building, and discuss the platform with other developers.

Use cases

Learn how you can build and deploy ambitious AI applications to Cloudflare's global network.

@CloudflareDev

Follow @CloudflareDev on Twitter to learn about product announcements, and what is new in Cloudflare Workers.

Edit page

Last updated: Mar 14, 2025

Next
Getting started
Resources
API
New to Cloudflare?
Products
Sponsorships
Open Source
Support
Help Center
System Status
Compliance
GDPR
Company
cloudflare.com
Our team
Careers
Tools
Cloudflare Radar
Speed Test
Is BGP Safe Yet?
RPKI Toolkit
Certificate Transparency
Community
X
Discord
YouTube
GitHub
2025 Cloudflare, Inc.
Privacy Policy
Terms of Use
Report Security Issues
Trademark
Cookie Preferences


=== Content from https://developers.cloudflare.com/workers-ai/models/ ===

Products
Workers AI
Models
Models
Copy Page
â–¼ TASKS
 Summarization
 Text Embeddings
 Text Classification
 Text Generation
 Object Detection
 Text-to-Image
 Image-to-Text
 Translation
 Text-to-Speech
 Image Classification
 Automatic Speech Recognition
â–¼ CAPABILITIES
 Batch
 LoRA
 Function calling
â–¼ AUTHORS
 facebook
 baai
 thebloke
 DeepSeek
 HuggingFace
 lykon
 tiiuae
 Black Forest Labs
 Google
 nousresearch
 meta-llama
 Meta
 llava-hf
 myshell-ai
 MistralAI
 MistralAI
 openchat
 Microsoft
 Qwen
 defog
 runwayml
 Stability.ai
 bytedance
 nexusflow
 tinyllama
 unum
 fblgit
 OpenAI
ðŸ“Œ
llama-4-scout-17b-16e-instruct
Text Generation â€¢ Meta

Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.

Function calling
ðŸ“Œ
llama-3.3-70b-instruct-fp8-fast
Text Generation â€¢ Meta

Llama 3.3 70B quantized to fp8 precision, optimized to be faster.

Batch
Function calling
ðŸ“Œ
llama-3.1-8b-instruct-fast
Text Generation â€¢ Meta

[Fast version] The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.

gemma-3-12b-it
Text Generation â€¢ Google

Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Gemma 3 models are multimodal, handling text and image input and generating text output, with a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions.

LoRA
mistral-small-3.1-24b-instruct
Text Generation â€¢ MistralAI

Building upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance. With 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks.

Function calling
qwq-32b
Text Generation â€¢ Qwen

QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.

LoRA
qwen2.5-coder-32b-instruct
Text Generation â€¢ Qwen

Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:

LoRA
B
bge-reranker-base
Text Classification â€¢ baai

Different from embedding model, reranker uses question and document as input and directly output similarity instead of embedding. You can get a relevance score by inputting query and passage to the reranker. And the score can be mapped to a float value in [0,1] by sigmoid function.

llama-guard-3-8b
Text Generation â€¢ Meta

Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM â€“ it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.

LoRA
deepseek-r1-distill-qwen-32b
Text Generation â€¢ DeepSeek

DeepSeek-R1-Distill-Qwen-32B is a model distilled from DeepSeek-R1 based on Qwen2.5. It outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.

llama-3.2-1b-instruct
Text Generation â€¢ Meta

The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.

llama-3.2-3b-instruct
Text Generation â€¢ Meta

The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.

llama-3.2-11b-vision-instruct
Text Generation â€¢ Meta

The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.

LoRA
flux-1-schnell
Text-to-Image â€¢ Black Forest Labs

FLUX.1 [schnell] is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.

llama-3.1-8b-instruct-awq
Text Generation â€¢ Meta

Quantized (int4) generative text model with 8 billion parameters from Meta.

llama-3.1-8b-instruct-fp8
Text Generation â€¢ Meta

Llama 3.1 8B quantized to FP8 precision

M
melotts
Text-to-Speech â€¢ myshell-ai

MeloTTS is a high-quality multi-lingual text-to-speech library by MyShell.ai.

llama-3.1-8b-instruct
Text Generation â€¢ Meta

The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.

B
bge-m3
Text Embeddings â€¢ baai

Multi-Functionality, Multi-Linguality, and Multi-Granularity embeddings model.

Batch
M
meta-llama-3-8b-instruct
Text Generation â€¢ meta-llama

Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.

whisper-large-v3-turbo
Automatic Speech Recognition â€¢ OpenAI

Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation.

llama-3-8b-instruct-awq
Text Generation â€¢ Meta

Quantized (int4) generative text model with 8 billion parameters from Meta.

L
llava-1.5-7b-hf
Beta
Image-to-Text â€¢ llava-hf

LLaVA is an open-source chatbot trained by fine-tuning LLaMA/Vicuna on GPT-generated multimodal instruction-following data. It is an auto-regressive language model, based on the transformer architecture.

F
una-cybertron-7b-v2-bf16
Beta
Text Generation â€¢ fblgit

Cybertron 7B v2 is a 7B MistralAI based model, best on it's series. It was trained with SFT, DPO and UNA (Unified Neural Alignment) on multiple datasets.

whisper-tiny-en
Beta
Automatic Speech Recognition â€¢ OpenAI

Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. This is the English-only version of the Whisper Tiny model which was trained on the task of speech recognition.

llama-3-8b-instruct
Text Generation â€¢ Meta

Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.

mistral-7b-instruct-v0.2
Beta
Text Generation â€¢ MistralAI

The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2. Mistral-7B-v0.2 has the following changes compared to Mistral-7B-v0.1: 32k context window (vs 8k context in v0.1), rope-theta = 1e6, and no Sliding-Window Attention.

LoRA
gemma-7b-it-lora
Beta
Text Generation â€¢ Google

This is a Gemma-7B base model that Cloudflare dedicates for inference with LoRA adapters. Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.

LoRA
gemma-2b-it-lora
Beta
Text Generation â€¢ Google

This is a Gemma-2B base model that Cloudflare dedicates for inference with LoRA adapters. Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.

LoRA
M
llama-2-7b-chat-hf-lora
Beta
Text Generation â€¢ meta-llama

This is a Llama2 base model that Cloudflare dedicated for inference with LoRA adapters. Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. This is the repository for the 7B fine-tuned model, optimized for dialogue use cases and converted for the Hugging Face Transformers format.

LoRA
gemma-7b-it
Beta
Text Generation â€¢ Google

Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants.

LoRA
N
starling-lm-7b-beta
Beta
Text Generation â€¢ nexusflow

We introduce Starling-LM-7B-beta, an open large language model (LLM) trained by Reinforcement Learning from AI Feedback (RLAIF). Starling-LM-7B-beta is trained from Openchat-3.5-0106 with our new reward model Nexusflow/Starling-RM-34B and policy optimization method Fine-Tuning Language Models from Human Preferences (PPO).

N
hermes-2-pro-mistral-7b
Beta
Text Generation â€¢ nousresearch

Hermes 2 Pro on Mistral 7B is the new flagship 7B Hermes! Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.

Function calling
mistral-7b-instruct-v0.2-lora
Beta
Text Generation â€¢ MistralAI

The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2.

LoRA
qwen1.5-1.8b-chat
Beta
Text Generation â€¢ Qwen

Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.

U
uform-gen2-qwen-500m
Beta
Image-to-Text â€¢ unum

UForm-Gen is a small generative vision-language model primarily designed for Image Captioning and Visual Question Answering. The model was pre-trained on the internal image captioning dataset and fine-tuned on public instructions datasets: SVIT, LVIS, VQAs datasets.

F
bart-large-cnn
Beta
Summarization â€¢ facebook

BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. You can use this model for text summarization.

phi-2
Beta
Text Generation â€¢ Microsoft

Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding.

T
tinyllama-1.1b-chat-v1.0
Beta
Text Generation â€¢ tinyllama

The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.

qwen1.5-14b-chat-awq
Beta
Text Generation â€¢ Qwen

Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.

qwen1.5-7b-chat-awq
Beta
Text Generation â€¢ Qwen

Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.

qwen1.5-0.5b-chat
Beta
Text Generation â€¢ Qwen

Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.

T
discolm-german-7b-v1-awq
Beta
Text Generation â€¢ thebloke

DiscoLM German 7b is a Mistral-based large language model with a focus on German-language applications. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.

T
falcon-7b-instruct
Beta
Text Generation â€¢ tiiuae

Falcon-7B-Instruct is a 7B parameters causal decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets.

O
openchat-3.5-0106
Beta
Text Generation â€¢ openchat

OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning.

D
sqlcoder-7b-2
Beta
Text Generation â€¢ defog

This model is intended to be used by non-technical users to understand data inside their SQL databases.

deepseek-math-7b-instruct
Beta
Text Generation â€¢ DeepSeek

DeepSeekMath-Instruct 7B is a mathematically instructed tuning model derived from DeepSeekMath-Base 7B. DeepSeekMath is initialized with DeepSeek-Coder-v1.5 7B and continues pre-training on math-related tokens sourced from Common Crawl, together with natural language and code data for 500B tokens.

F
detr-resnet-50
Beta
Object Detection â€¢ facebook

DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images).

B
stable-diffusion-xl-lightning
Beta
Text-to-Image â€¢ bytedance

SDXL-Lightning is a lightning-fast text-to-image generation model. It can generate high-quality 1024px images in a few steps.

L
dreamshaper-8-lcm
Beta
Text-to-Image â€¢ lykon

Stable Diffusion model that has been fine-tuned to be better at photorealism without sacrificing range.

R
stable-diffusion-v1-5-img2img
Beta
Text-to-Image â€¢ runwayml

Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images. Img2img generate a new image from an input image with Stable Diffusion.

R
stable-diffusion-v1-5-inpainting
Beta
Text-to-Image â€¢ runwayml

Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask.

T
deepseek-coder-6.7b-instruct-awq
Beta
Text Generation â€¢ thebloke

Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.

T
deepseek-coder-6.7b-base-awq
Beta
Text Generation â€¢ thebloke

Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.

T
llamaguard-7b-awq
Beta
Text Generation â€¢ thebloke

Llama Guard is a model for classifying the safety of LLM prompts and responses, using a taxonomy of safety risks.

T
neural-chat-7b-v3-1-awq
Beta
Text Generation â€¢ thebloke

This model is a fine-tuned 7B parameter LLM on the Intel Gaudi 2 processor from the mistralai/Mistral-7B-v0.1 on the open source dataset Open-Orca/SlimOrca.

T
openhermes-2.5-mistral-7b-awq
Beta
Text Generation â€¢ thebloke

OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which trained on additional code datasets.

T
llama-2-13b-chat-awq
Beta
Text Generation â€¢ thebloke

Llama 2 13B Chat AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Llama 2 variant.

T
mistral-7b-instruct-v0.1-awq
Beta
Text Generation â€¢ thebloke

Mistral 7B Instruct v0.1 AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Mistral variant.

T
zephyr-7b-beta-awq
Beta
Text Generation â€¢ thebloke

Zephyr 7B Beta AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Zephyr model variant.

stable-diffusion-xl-base-1.0
Beta
Text-to-Image â€¢ Stability.ai

Diffusion-based text-to-image generative model by Stability AI. Generates and modify images based on text prompts.

B
bge-large-en-v1.5
Text Embeddings â€¢ baai

BAAI general embedding (Large) model that transforms any given text into a 1024-dimensional vector

Batch
B
bge-small-en-v1.5
Text Embeddings â€¢ baai

BAAI general embedding (Small) model that transforms any given text into a 384-dimensional vector

Batch
llama-2-7b-chat-fp16
Text Generation â€¢ Meta

Full precision (fp16) generative text model with 7 billion parameters from Meta

mistral-7b-instruct-v0.1
Text Generation â€¢ MistralAI

Instruct fine-tuned version of the Mistral-7b generative text model with 7 billion parameters

LoRA
B
bge-base-en-v1.5
Text Embeddings â€¢ baai

BAAI general embedding (Base) model that transforms any given text into a 768-dimensional vector

Batch
distilbert-sst-2-int8
Text Classification â€¢ HuggingFace

Distilled BERT model that was finetuned on SST-2 for sentiment classification

llama-2-7b-chat-int8
Text Generation â€¢ Meta

Quantized (int8) generative text model with 7 billion parameters from Meta

m2m100-1.2b
Translation â€¢ Meta

Multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation

Batch
resnet-50
Image Classification â€¢ Microsoft

50 layers deep image classification CNN trained on more than 1M images from ImageNet

whisper
Automatic Speech Recognition â€¢ OpenAI

Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.

llama-3.1-70b-instruct
Text Generation â€¢ Meta

The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.

Was this helpful?
Previous
Dashboard
Next
Workers Bindings
Resources
API
New to Cloudflare?
Products
Sponsorships
Open Source
Support
Help Center
System Status
Compliance
GDPR
Company
cloudflare.com
Our team
Careers
Tools
Cloudflare Radar
Speed Test
Is BGP Safe Yet?
RPKI Toolkit
Certificate Transparency
Community
X
Discord
YouTube
GitHub
2025 Cloudflare, Inc.
Privacy Policy
Terms of Use
Report Security Issues
Trademark
Cookie Preferences


=== Content from https://developers.cloudflare.com/workers-ai/ ===

Products
Workers AI
Cloudflare Workers AI
Copy Page

Run machine learning models, powered by serverless GPUs, on Cloudflare's global network.

Available on Free and Paid plans

Workers AI allows you to run AI models in a serverless way, without having to worry about scaling, maintaining, or paying for unused infrastructure. You can invoke models running on GPUs on Cloudflare's network from your own code â€” from Workers, Pages, or anywhere via the Cloudflare API.

Workers AI gives you access to:

50+ open-source models, available as a part of our model catalog
Serverless, pay-for-what-you-use pricing model
All as part of a fully-featured developer platform, including AI Gateway, Vectorize, Workers and more...
Get started Watch a Workers AI demo

Custom requirements

If you have custom requirements like private custom models or higher limits, complete the Custom Requirements Form â†—. Cloudflare will contact you with next steps.

Workers AI is now Generally Available

To report bugs or give feedback, go to the #workers-ai Discord channel â†—. If you are having issues with Wrangler, report issues in the Wrangler GitHub repository â†—.

Features
Models

Workers AI comes with a curated set of popular open-source models that enable you to do tasks such as image classification, text generation, object detection and more.

Browse models
Related products
AI Gateway

Observe and control your AI applications with caching, rate limiting, request retries, model fallback, and more.

Vectorize

Build full-stack AI applications with Vectorize, Cloudflareâ€™s vector database. Adding Vectorize enables you to perform tasks such as semantic search, recommendations, anomaly detection or can be used to provide context and memory to an LLM.

Workers

Build serverless applications and deploy instantly across the globe for exceptional performance, reliability, and scale.

Pages

Create full-stack applications that are instantly deployed to the Cloudflare global network.

R2

Store large amounts of unstructured data without the costly egress bandwidth fees associated with typical cloud storage services.

D1

Create new serverless SQL databases to query from your Workers and Pages projects.

Durable Objects

A globally distributed coordination API with strongly consistent storage.

KV

Create a global, low-latency, key-value data storage.

More resources

Get started

Build and deploy your first Workers AI application.

Plans

Learn about Free and Paid plans.

Limits

Learn about Workers AI limits.

Use cases

Learn how you can build and deploy ambitious AI applications to Cloudflare's global network.

Storage options

Learn which storage option is best for your project.

Developer Discord

Connect with the Workers community on Discord to ask questions, share what you are building, and discuss the platform with other developers.

@CloudflareDev

Follow @CloudflareDev on Twitter to learn about product announcements, and what is new in Cloudflare Workers.

Edit page

Last updated: Mar 14, 2025

Next
Getting started
Resources
API
New to Cloudflare?
Products
Sponsorships
Open Source
Support
Help Center
System Status
Compliance
GDPR
Company
cloudflare.com
Our team
Careers
Tools
Cloudflare Radar
Speed Test
Is BGP Safe Yet?
RPKI Toolkit
Certificate Transparency
Community
X
Discord
YouTube
GitHub
2025 Cloudflare, Inc.
Privacy Policy
Terms of Use
Report Security Issues
Trademark
Cookie Preferences


=== Content from https://developers.cloudflare.com/vectorize/ ===

Products
Vectorize
Cloudflare Vectorize
Copy Page

Build full-stack AI applications with Vectorize, Cloudflare's powerful vector database.

Vectorize is a globally distributed vector database that enables you to build full-stack, AI-powered applications with Cloudflare Workers. Vectorize makes querying embeddings â€” representations of values or objects like text, images, audio that are designed to be consumed by machine learning models and semantic search algorithms â€” faster, easier and more affordable.

Vectorize is now Generally Available

To report bugs or give feedback, go to the #vectorize Discord channel â†—. If you are having issues with Wrangler, report issues in the Wrangler GitHub repository â†—.

For example, by storing the embeddings (vectors) generated by a machine learning model, including those built-in to Workers AI or by bringing your own from platforms like OpenAI, you can build applications with powerful search, similarity, recommendation, classification and/or anomaly detection capabilities based on your own data.

The vectors returned can reference images stored in Cloudflare R2, documents in KV, and/or user profiles stored in D1 â€” enabling you to go from vector search result to concrete object all within the Workers platform, and without standing up additional infrastructure.

Features
Vector database

Learn how to create your first Vectorize database, upload vector embeddings, and query those embeddings from Cloudflare Workers.

Create your Vector database
Vector embeddings using Workers AI

Learn how to use Vectorize to generate vector embeddings using Workers AI.

Create vector embeddings using Workers AI
Search using Vectorize and AutoRAG

Learn how to automatically index your data and store it in Vectorize, then query it to generate context-aware responses using AutoRAG.

Build a RAG with Vectorize
Related products
Workers AI

Run machine learning models, powered by serverless GPUs, on Cloudflareâ€™s global network.

R2 Storage

Store large amounts of unstructured data without the costly egress bandwidth fees associated with typical cloud storage services.

More resources

Limits

Learn about Vectorize limits and how to work within them.

Use cases

Learn how you can build and deploy ambitious AI applications to Cloudflare's global network.

Storage options

Learn more about the storage and database options you can build on with Workers.

Developer Discord

Connect with the Workers community on Discord to ask questions, join the #vectorize channel to show what you are building, and discuss the platform with other developers.

@CloudflareDev

Follow @CloudflareDev on Twitter to learn about product announcements, and what is new in Cloudflare Developer Platform.

Edit page

Last updated: Apr 6, 2025

Next
Introduction to Vectorize
Resources
API
New to Cloudflare?
Products
Sponsorships
Open Source
Support
Help Center
System Status
Compliance
GDPR
Company
cloudflare.com
Our team
Careers
Tools
Cloudflare Radar
Speed Test
Is BGP Safe Yet?
RPKI Toolkit
Certificate Transparency
Community
X
Discord
YouTube
GitHub
2025 Cloudflare, Inc.
Privacy Policy
Terms of Use
Report Security Issues
Trademark
Cookie Preferences


=== Content from https://developers.cloudflare.com/vectorize/get-started/ ===

Products
Vectorize
Get started
Get started
Copy Page
Introduction to Vectorize
Vectorize and Workers AI
Edit page

Last updated: Feb 21, 2025

Next
Overview
Resources
API
New to Cloudflare?
Products
Sponsorships
Open Source
Support
Help Center
System Status
Compliance
GDPR
Company
cloudflare.com
Our team
Careers
Tools
Cloudflare Radar
Speed Test
Is BGP Safe Yet?
RPKI Toolkit
Certificate Transparency
Community
X
Discord
YouTube
GitHub
2025 Cloudflare, Inc.
Privacy Policy
Terms of Use
Report Security Issues
Trademark
Cookie Preferences


=== Content from https://developers.cloudflare.com/vectorize/configuration/ ===

Products
Vectorize
Best practices
Best practices
Copy Page
Create indexes
Insert vectors
Query vectors
Edit page

Last updated: Feb 21, 2025

Next
Overview
Resources
API
New to Cloudflare?
Products
Sponsorships
Open Source
Support
Help Center
System Status
Compliance
GDPR
Company
cloudflare.com
Our team
Careers
Tools
Cloudflare Radar
Speed Test
Is BGP Safe Yet?
RPKI Toolkit
Certificate Transparency
Community
X
Discord
YouTube
GitHub
2025 Cloudflare, Inc.
Privacy Policy
Terms of Use
Report Security Issues
Trademark
Cookie Preferences